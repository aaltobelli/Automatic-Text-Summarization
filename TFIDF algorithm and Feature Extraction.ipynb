{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import re\r\n",
    "import requests\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import math\r\n",
    "import nltk\r\n",
    "import csv\r\n",
    "import statistics as st\r\n",
    "from rouge_score import rouge_scorer\r\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/aldo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# General Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Counts the documents in a category (in the entire collection if category not specified)\r\n",
    "def count_docs(collection, category=\"*\"):\r\n",
    "    r = requests.get('http://localhost:8984/solr/'+collection+'/select?q=category:'+category+'&wt=json').json()\r\n",
    "    return r['response']['numFound']\r\n",
    "\r\n",
    "#Returns a document given its docId\r\n",
    "def get_doc(collection, docId):\r\n",
    "    r = requests.get('http://localhost:8984/solr/'+collection+'/select?q=docId:'+str(docId)+'&wt=json').json()\r\n",
    "    return r['response']['docs'][0]\r\n",
    "\r\n",
    "#Runs the custom analyzer on a sentence and returns a list of tokens\r\n",
    "def analyze(sentence):\r\n",
    "    sentenceT = re.sub('[\\\"\\'&#]', ' ', sentence)\r\n",
    "    r = requests.get('http://localhost:8984/solr/myDocs/stream?expr=analyze(\\\"'+sentenceT+'\\\", full_text)').json()\r\n",
    "    return r['result-set']['docs'][0]['return-value']\r\n",
    "\r\n",
    "#Extracts a list of sentences from a document\r\n",
    "def extract_sentences(document):\r\n",
    "    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', document)\r\n",
    "    sentences = [x.replace('\"', \"\").replace(\"'\", \"\") for x in sentences if x]\r\n",
    "    return list(filter(None, sentences))\r\n",
    "\r\n",
    "#Computes the cosine similarity of two documents' weighted vectors\r\n",
    "def cosine_similarity(wvA, wvB):\r\n",
    "    num = 0\r\n",
    "    den1 = 0\r\n",
    "    den2 = 0\r\n",
    "    for i in range(0, len(wvA)):\r\n",
    "        num += wvA[i]*wvB[i]\r\n",
    "        den1 += wvA[i]*wvA[i]\r\n",
    "        den2 += wvB[i]*wvB[i]\r\n",
    "    den = math.sqrt(den1)*math.sqrt(den2)\r\n",
    "    try:\r\n",
    "        res = num/den\r\n",
    "    except ZeroDivisionError:\r\n",
    "        res = 0.0\r\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Returns the idf value of a term, based on the specified field \r\n",
    "def idf(field, term, docId):\r\n",
    "    r = requests.get('http://localhost:8984/solr/myDocs/select?q=docId:'+str(docId)+'&fl=idf('+field+','+term+'),*&wt=json').json()\r\n",
    "    return r['response']['docs'][0]['idf('+field+','+term+')']\r\n",
    "\r\n",
    "#Returns the tf values of a term, in document with docId\r\n",
    "def tf(field, term, docId):\r\n",
    "    r = requests.get('http://localhost:8984/solr/myDocs/select?q=docId:'+str(docId)+'&fl=tf('+field+','+term+'),*&wt=json').json()\r\n",
    "    return r['response']['docs'][0]['tf('+field+','+term+')']\r\n",
    "\r\n",
    "def generate_summary(docId):\r\n",
    "    doc = get_doc(\"myDocs\", docId)\r\n",
    "    sentences = extract_sentences(doc['full_text'])\r\n",
    "    scores = []\r\n",
    "    for sentence in sentences:\r\n",
    "        score = 0\r\n",
    "        analyzedSentence = analyze(sentence)\r\n",
    "        for elem in analyzedSentence:\r\n",
    "            score+= tf(\"full_text\", elem, docId)*idf(\"full_text\", elem, docId)   \r\n",
    "        scores.append(score/len(analyzedSentence))\r\n",
    "    \r\n",
    "    scores = np.array(scores)\r\n",
    "    topIdx = np.sort(np.argsort(scores)[-math.ceil(len(sentences)/3):])\r\n",
    "    topValues = [sentences[i] for i in topIdx]\r\n",
    "    return (\". \".join(topValues)+\".\")\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Summary Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "summaries = []\r\n",
    "for i in range(0, 100):\r\n",
    "    summaries.append({\"docId\":i, \"hypotesis\":generate_summary(i), \"reference\":get_doc(\"myDocs\", i)['summary'] })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def mean_score(summaries, rouge, scope):\r\n",
    "    scorer = rouge_scorer.RougeScorer([rouge])\r\n",
    "    scores = []\r\n",
    "    for i in range(100):\r\n",
    "        hyp = summaries[i]['hypotesis']\r\n",
    "        ref = summaries[i]['reference']\r\n",
    "        if scope == \"precision\":\r\n",
    "            scores.append(scorer.score(hyp, ref)[rouge].precision)\r\n",
    "        elif scope == \"recall\":\r\n",
    "            scores.append(scorer.score(hyp, ref)[rouge].recall)\r\n",
    "        elif scope == \"fmeasure\":\r\n",
    "            scores.append(scorer.score(hyp, ref)[rouge].fmeasure)\r\n",
    "    return st.mean(scores)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5776129097369671\n",
      "0.761491938020721\n",
      "0.6537314611777362\n",
      "\n",
      "0.49015608237983693\n",
      "0.6470373099065739\n",
      "0.5551377897721256\n",
      "\n",
      "0.4562320433604605\n",
      "0.6036472285303791\n",
      "0.5172375287688392\n",
      "\n",
      "0.4019874712308498\n",
      "0.5301989321686369\n",
      "0.4549990602243374\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_article_info(docId):\r\n",
    "    expression= \"let(echo=\\\"a, b, c, d\\\", a=select(search(mySentences,\\\r\n",
    "    q=\\\"docId:\"+str(docId)+\"\\\", fl=\\\"sentence\\\", rows=1000), \\\r\n",
    "    analyze(sentence, sentence) as terms),\\\r\n",
    "    b=termVectors(a, minTermLength=0, minDocFreq=0, maxDocFreq=1),\\\r\n",
    "    c=getColumnLabels(b), \\\r\n",
    "    d=search(mySentences, q=\\\"docId:\"+str(docId)+\"\\\", fl=\\\"sentence, title, summary\\\", rows=1000))\"\r\n",
    "\r\n",
    "    response = requests.get('http://localhost:8984/solr/mySentences/stream?expr='+expression).json()\r\n",
    "\r\n",
    "    dictionary = response['result-set']['docs'][0]['c']            \r\n",
    "    sentenceTerms = response['result-set']['docs'][0]['a']          \r\n",
    "    weightedVectors = response['result-set']['docs'][0]['b']\r\n",
    "    title = response['result-set']['docs'][0]['d'][0]['title']\r\n",
    "    \r\n",
    "    sentences = []\r\n",
    "    classes = []\r\n",
    "    for elem in response['result-set']['docs'][0]['d']:    \r\n",
    "        sentences.append(elem['sentence'])\r\n",
    "        classes.append(elem['summary'])\r\n",
    "    \r\n",
    "    return {\"title\":title, \"sentences\":sentences, \"classes\": classes, \"sentenceTerms\":sentenceTerms,\r\n",
    "            \"weightedVectors\":weightedVectors, \"dictionary\":dictionary}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Article-Independent Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def sentence_lengths(sentenceTerms):\r\n",
    "    weights = []\r\n",
    "    for terms in sentenceTerms:\r\n",
    "        weights.append(len(terms['terms']))\r\n",
    "    return weights\r\n",
    "\r\n",
    "def pos_tagging_features(sentence):\r\n",
    "    sentenceT = re.sub('[\\\"\\'&#]', ' ', sentence)\r\n",
    "    r = requests.get('http://localhost:8984/solr/mySentences/stream?expr=analyze(\\\"'+sentenceT+'\\\", simpleTokenizer)').json()\r\n",
    "    tagged = nltk.pos_tag(r['result-set']['docs'][0]['return-value'])\r\n",
    "\r\n",
    "    properNouns = [word for (word, pos) in tagged if (pos == 'NNP' or pos == 'NNPS')]\r\n",
    "    nouns = [word for (word, pos) in tagged if (pos == 'NN' or pos == 'NNS' or pos == 'NNP' or pos == 'NNPS')]\r\n",
    "    verbs = [word for (word, pos) in tagged if (pos == 'VB' or pos == 'VBG' or pos == 'VBD' or pos == 'VBN' or pos == 'VBP' or pos == 'VBZ')]\r\n",
    "    adjectives = [word for (word, pos) in tagged if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS')]\r\n",
    "    adverbs = [word for (word, pos) in tagged if (pos == 'RB' or pos == 'RBR' or pos == 'RBS')]\r\n",
    "    \r\n",
    "    if not properNouns:\r\n",
    "        proper = False\r\n",
    "    else: proper = True\r\n",
    "    \r\n",
    "    if tagged:\r\n",
    "        nounRatio = len(nouns)/len(tagged)\r\n",
    "        verbRatio = len(verbs)/len(tagged)\r\n",
    "        adjectiveRatio = len(adjectives)/len(tagged)\r\n",
    "        adverbRatio = len(adverbs)/len(tagged)\r\n",
    "    else: nounRatio = verbRatio = adjectiveRatio = adverbRatio = 0.0\r\n",
    "    \r\n",
    "    return {\"proper\":proper, \"nounRatio\":nounRatio, \r\n",
    "            \"verbRatio\":verbRatio, \"adjectiveRatio\":adjectiveRatio, \r\n",
    "            \"adverbRatio\":adverbRatio}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Article-Dependent Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def sentence_positions(sentences):\r\n",
    "    nSent = len(sentences)\r\n",
    "    return [x/nSent for x in list(range(0, nSent))]\r\n",
    "\r\n",
    "def title_similarities(sentences, title):\r\n",
    "    weights = []\r\n",
    "    titleTerms = analyze(title)\r\n",
    "    for sentence in sentences:\r\n",
    "        sentenceTerms = analyze(sentence)\r\n",
    "        try:\r\n",
    "            commonTerms = len([x for x in sentenceTerms if x in titleTerms])/len(sentenceTerms)\r\n",
    "        except ZeroDivisionError:\r\n",
    "            commonTerms = 0.0\r\n",
    "        weights.append(commonTerms)\r\n",
    "    return weights\r\n",
    "\r\n",
    "def sent_to_sent_cohesion(weightedVectors):\r\n",
    "    rawValues = []\r\n",
    "    for i in range(0, len(weightedVectors)):\r\n",
    "        score = 0\r\n",
    "        for j in range(0, len(weightedVectors)):\r\n",
    "            if j!=i:\r\n",
    "                score += cosine_similarity(weightedVectors[i], weightedVectors[j])\r\n",
    "        rawValues.append(score)\r\n",
    "    scores = [element/max(rawValues) for element in rawValues]\r\n",
    "    return scores\r\n",
    "\r\n",
    "def sent_to_centroid_cohesion(weightedVectors):\r\n",
    "    centroid = np.zeros(len(weightedVectors[0]))\r\n",
    "    for vector in weightedVectors:\r\n",
    "        centroid += np.array(vector)\r\n",
    "    centroid = (centroid/len(weightedVectors)).tolist()\r\n",
    "    rawValues = []\r\n",
    "    for vector in weightedVectors:\r\n",
    "        score = cosine_similarity(vector, centroid)\r\n",
    "        rawValues.append(score)\r\n",
    "\r\n",
    "    scores = [element/max(rawValues) for element in rawValues]\r\n",
    "    return scores  \r\n",
    "\r\n",
    "def tf_isf(weightedVectors):\r\n",
    "    #doc = get_doc_info(docId)\r\n",
    "    weights = []\r\n",
    "    for elem in weightedVectors:\r\n",
    "        temp = [x for x in elem if x !=0]\r\n",
    "        weights.append(sum(temp)/len(temp))\r\n",
    "    return weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def extract_features(docId):\r\n",
    "    doc = get_article_info(docId)\r\n",
    "    sentences = doc['sentences']\r\n",
    "    classes = doc['classes']\r\n",
    "    sentPos = sentence_positions(sentences)\r\n",
    "    titleSim = title_similarities(sentences, doc['title'])\r\n",
    "    sentLen = sentence_lengths(doc['sentenceTerms'])\r\n",
    "    stsCoh = sent_to_sent_cohesion(doc['weightedVectors'])\r\n",
    "    stcCoh = sent_to_centroid_cohesion(doc['weightedVectors'])\r\n",
    "    \r\n",
    "    features = []\r\n",
    "    for i in range(0, len(sentences)):\r\n",
    "        generalFeatures = {\"sentence\":sentences[i], \"docId\":docId, \"sentPos\":sentPos[i], \r\n",
    "                            \"titleSim\":titleSim[i], \"sentLen\":sentLen[i],\r\n",
    "                            \"stsCoh\":stsCoh[i], \"stcCoh\":stcCoh[i]}\r\n",
    "        posFeatures = pos_tagging_features(sentences[i])\r\n",
    "        classSumm = {\"class\": classes[i]}\r\n",
    "        features.append({**generalFeatures, **posFeatures, **classSumm})\r\n",
    "    \r\n",
    "    return features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Export Features to CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "feats = []\r\n",
    "length = count_docs(\"myDocs\")\r\n",
    "for i in range(0, length):\r\n",
    "    feats.extend(extract_features(i))\r\n",
    "    \r\n",
    "csv_columns = ['sentence','docId','sentPos','titleSim',\r\n",
    "               'sentLen', 'stsCoh', 'stcCoh', 'proper', 'nounRatio', 'verbRatio',\r\n",
    "              'adjectiveRatio', 'adverbRatio', 'class']\r\n",
    "dict_data = feats\r\n",
    "csv_file = \"features.csv\"\r\n",
    "try:\r\n",
    "    with open(csv_file, 'w') as csvfile:\r\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\r\n",
    "        writer.writeheader()\r\n",
    "        for data in dict_data:\r\n",
    "            writer.writerow(data)\r\n",
    "except IOError:\r\n",
    "    print(\"I/O error\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}